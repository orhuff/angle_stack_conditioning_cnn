{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f222e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import segyio\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b381b58",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1bbad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segy copying and writing function\n",
    "def block_write_mmap(output_segy, input_segy, data_cube, mmap=True):\n",
    "    copyfile(input_segy, output_segy)\n",
    "\n",
    "    with segyio.open(output_segy, \"r\") as segy_src:\n",
    "        n_xl = len(segy_src.xlines)\n",
    "        n_il = len(segy_src.ilines)\n",
    "        n_smpl = len(segy_src.samples)\n",
    "        expected_shape = (n_il, n_xl, n_smpl)\n",
    "    with segyio.open(output_segy, \"r+\", ignore_geometry=True) as segy_dst:\n",
    "        if mmap:\n",
    "            mapped_success = segy_dst.mmap()\n",
    "        if data_cube.shape != expected_shape:\n",
    "            raise ValueError(\n",
    "                f\"dataset has shape {data_cube.shape} which is not the expected shape {expected_shape}\")\n",
    "        data_cube = np.ascontiguousarray(data_cube, 'float32')\n",
    "        segy_dst.trace.raw[:] = data_cube.reshape((n_xl * n_il, n_smpl))\n",
    "        print('Done writing ' + output_segy)\n",
    "        return mapped_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e36c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full loading, prediction, and writing function\n",
    "def condition_angle_stacks(model_h5, t_max, near_inp_segy, mid_inp_segy, far_inp_segy, near_out_segy, mid_out_segy, far_out_segy):\n",
    "    \n",
    "    # load original data as numpy arrays\n",
    "    near_orig = segyio.tools.cube(near_inp_segy)\n",
    "    mid_orig = segyio.tools.cube(mid_inp_segy)\n",
    "    far_orig = segyio.tools.cube(far_inp_segy)\n",
    "    \n",
    "    # load trained model\n",
    "    model = tf.keras.models.load_model(model_h5, compile=False)\n",
    "\n",
    "    # retain original time length of data\n",
    "    t_orig = near_orig.shape[2]\n",
    "    \n",
    "    # if the original seismic data has fewer time samples than the tmax of the model\n",
    "    if t_orig < t_max:\n",
    "        \n",
    "        # pad the data with zeros at the end to make it the same length tmax\n",
    "        zeros_to_add_before = t_max - t_orig\n",
    "        zero_array_before = np.zeros((near_orig.shape[0], near_orig.shape[1], zeros_to_add_before))\n",
    "        near_orig = np.concatenate((near_orig, zero_array_before), axis=2)\n",
    "        mid_orig = np.concatenate((mid_orig, zero_array_before), axis=2)\n",
    "        far_orig = np.concatenate((far_orig, zero_array_before), axis=2)\n",
    "        \n",
    "    # if the original data has more samples (or the same) as tmax\n",
    "    else:\n",
    "\n",
    "        near_orig = near_orig[:, :, :t_max]\n",
    "        mid_orig = mid_orig[:, :, :t_max]\n",
    "        far_orig = far_orig[:, :, :t_max]\n",
    "\n",
    "    # initialize arrays for cnn prediction\n",
    "    near_cnn = np.zeros(near_orig.shape)\n",
    "    mid_cnn = np.zeros(mid_orig.shape)\n",
    "    far_cnn = np.zeros(far_orig.shape)\n",
    "\n",
    "    # iterate over crossline number\n",
    "    for xline in range(near_orig.shape[1]):\n",
    "\n",
    "        # iterate over inline number\n",
    "        counter = 1\n",
    "        for inline in range(near_orig.shape[0]):\n",
    "\n",
    "            # combine near,mid,far into stacked array, and reshape for tensorflow format\n",
    "            orig_stacks = np.stack((near_orig[inline, xline, :], mid_orig[inline, xline, :], far_orig[inline, xline, :]), axis=1)\n",
    "            orig_stacks = np.reshape(orig_stacks, (1, t_max, 3, 1))\n",
    "\n",
    "            # make prediction with model, and extract it from tensorflow format\n",
    "            pred_stacks = model.predict(orig_stacks, verbose=False)\n",
    "            pred_stacks = pred_stacks[0,:,:]      \n",
    "\n",
    "            # fill in cnn prediction arrays\n",
    "            near_cnn[inline, xline, :] = pred_stacks[:,0]\n",
    "            mid_cnn[inline, xline, :] = pred_stacks[:,1]\n",
    "            far_cnn[inline, xline, :] = pred_stacks[:,2]\n",
    "\n",
    "            # print out progress every 400 CDP locations\n",
    "            if counter % 400 == 0:\n",
    "                print('XL = '+str(xline+1)+' / '+str(near_orig.shape[1])+'  |  IL = '+ str(inline+1)+' / '+str(near_orig.shape[0]))\n",
    "            counter += 1\n",
    "            \n",
    "    # normalize CNN-predicted amplitudes to same level as average of original amplitudes\n",
    "    norm_near = np.mean(np.abs(near_orig)) / np.mean(np.abs(near_cnn))\n",
    "    norm_mid = np.mean(np.abs(mid_orig)) / np.mean(np.abs(mid_cnn))\n",
    "    norm_far = np.mean(np.abs(far_orig)) / np.mean(np.abs(far_cnn))\n",
    "\n",
    "    near_cnn *= norm_near\n",
    "    mid_cnn *= norm_mid\n",
    "    far_cnn *= norm_far\n",
    "    \n",
    "    print(' ')\n",
    "    print('DONE MAKING PREDICTIONS')\n",
    "    print(' ')\n",
    "\n",
    "    # if the original seismic data had more time samples than the tmax of the model\n",
    "    if t_orig > t_max:\n",
    "        \n",
    "        # calculate number of zeros to add back to array, for writing back to initial segy geometry\n",
    "        zeros_to_add_after = t_orig - t_max\n",
    "\n",
    "        # pad the prediction arrays past 1248 samples with zeros\n",
    "        zero_array_after = np.zeros((near_orig.shape[0], near_orig.shape[1], zeros_to_add_after))\n",
    "        near_cnn_pad = np.concatenate((near_cnn, zero_array_after), axis=2)\n",
    "        mid_cnn_pad = np.concatenate((mid_cnn, zero_array_after), axis=2)\n",
    "        far_cnn_pad = np.concatenate((far_cnn, zero_array_after), axis=2)\n",
    "        \n",
    "    # if the original seismic data had fewer time samples (or the same) than the tmax of the model    \n",
    "    else:\n",
    "        \n",
    "        near_cnn_pad = near_cnn[:, :, :t_orig]\n",
    "        mid_cnn_pad = mid_cnn[:, :, :t_orig]\n",
    "        far_cnn_pad = far_cnn[:, :, :t_orig]\n",
    "        \n",
    "    # write near, mid, and far segy prediction files\n",
    "    block_write_mmap(near_out_segy, near_inp_segy, near_cnn_pad, mmap=True)\n",
    "    block_write_mmap(mid_out_segy, mid_inp_segy, mid_cnn_pad, mmap=True)\n",
    "    block_write_mmap(far_out_segy, far_inp_segy, far_cnn_pad, mmap=True)\n",
    "    print('')\n",
    "    \n",
    "    return 'ALL FILES WRITTEN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22514b3f",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9788d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m far_out_segy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfar_cube_CNN.sgy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# call function\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mcondition_angle_stacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_h5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnear_inp_segy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmid_inp_segy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfar_inp_segy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnear_out_segy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmid_out_segy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfar_out_segy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mcondition_angle_stacks\u001b[1;34m(model_h5, t_max, near_inp_segy, mid_inp_segy, far_inp_segy, near_out_segy, mid_out_segy, far_out_segy)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcondition_angle_stacks\u001b[39m(model_h5, t_max, near_inp_segy, mid_inp_segy, far_inp_segy, near_out_segy, mid_out_segy, far_out_segy):\n\u001b[0;32m      3\u001b[0m     \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# load original data as numpy arrays\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     near_orig \u001b[38;5;241m=\u001b[39m \u001b[43msegyio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcube\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnear_inp_segy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     mid_orig \u001b[38;5;241m=\u001b[39m segyio\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mcube(mid_inp_segy)\n\u001b[0;32m      7\u001b[0m     far_orig \u001b[38;5;241m=\u001b[39m segyio\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mcube(far_inp_segy)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\segyio\\tools.py:236\u001b[0m, in \u001b[0;36mcube\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Read a full cube from a file\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mTakes an open segy file (created with segyio.open) or a file name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, segyio\u001b[38;5;241m.\u001b[39mSegyFile):\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msegyio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fl:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cube(fl)\n\u001b[0;32m    239\u001b[0m ilsort \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39msorting \u001b[38;5;241m==\u001b[39m segyio\u001b[38;5;241m.\u001b[39mTraceSortingFormat\u001b[38;5;241m.\u001b[39mINLINE_SORTING\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\segyio\\open.py:162\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename, mode, iline, xline, strict, ignore_geometry, endian)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(problem\u001b[38;5;241m.\u001b[39mformat(endian) \u001b[38;5;241m+\u001b[39m opts)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _segyio\n\u001b[1;32m--> 162\u001b[0m fd \u001b[38;5;241m=\u001b[39m \u001b[43m_segyio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegyiofd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendians\u001b[49m\u001b[43m[\u001b[49m\u001b[43mendian\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m fd\u001b[38;5;241m.\u001b[39msegyopen()\n\u001b[0;32m    164\u001b[0m metrics \u001b[38;5;241m=\u001b[39m fd\u001b[38;5;241m.\u001b[39mmetrics()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "t_max = 1248\n",
    "\n",
    "# set these as the paths to the model file, the near/mid/far input segys, and desired name/path for writing results\n",
    "model_h5 = 'unet-resnet-102030.h5'\n",
    "\n",
    "near_inp_segy = 'near_cube.sgy'\n",
    "mid_inp_segy = 'mid_cube.sgy'\n",
    "far_inp_segy = 'far_cube.sgy'\n",
    "\n",
    "near_out_segy = 'near_cube_CNN.sgy'\n",
    "mid_out_segy = 'mid_cube_CNN.sgy'\n",
    "far_out_segy = 'far_cube_CNN.sgy'\n",
    "\n",
    "# call function\n",
    "condition_angle_stacks(model_h5, t_max, near_inp_segy, mid_inp_segy, far_inp_segy, near_out_segy, mid_out_segy, far_out_segy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1178a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
